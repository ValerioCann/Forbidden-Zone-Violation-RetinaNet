{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fa5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Forbidden Zone Violation (RetinaNet, TorchVision, OpenCV)\n",
    "# Goal:\n",
    "#   - Detect persons & vehicles with RetinaNet (COCO).\n",
    "#   - A 6-point polygon defines a pedestrian-only area (ROI).\n",
    "#   - Count a violation when a vehicle enters the ROI.\n",
    "#   - HUD: violation counter (top-left) + \"Alert\" bottom-center.\n",
    "#   - Colors are provided directly in BGR (OpenCV order).\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a66259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa32f5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 1: (px) 2, 655\n",
      "Point 2: (px) 2, 435\n",
      "Point 3: (px) 180, 238\n",
      "Point 4: (px) 1092, 221\n",
      "Point 5: (px) 1277, 369\n",
      "Point 6: (px) 1277, 655\n",
      "\n",
      "Paste this into ROI_NORM_PTS in your main script:\n",
      "ROI_NORM_PTS = [\n",
      "    (0.0016, 0.997),\n",
      "    (0.0016, 0.6621),\n",
      "    (0.1407, 0.3623),\n",
      "    (0.8538, 0.3364),\n",
      "    (0.9984, 0.5616),\n",
      "    (0.9984, 0.997),\n",
      "]\n",
      "\n",
      "\n",
      "Paste this into ROI_NORM_PTS in your main script:\n",
      "ROI_NORM_PTS = [\n",
      "    (0.0016, 0.997),\n",
      "    (0.0016, 0.6621),\n",
      "    (0.1407, 0.3623),\n",
      "    (0.8538, 0.3364),\n",
      "    (0.9984, 0.5616),\n",
      "    (0.9984, 0.997),\n",
      "]\n",
      "\n",
      "\n",
      "Paste this into ROI_NORM_PTS in your main script:\n",
      "ROI_NORM_PTS = [\n",
      "    (0.0016, 0.997),\n",
      "    (0.0016, 0.6621),\n",
      "    (0.1407, 0.3623),\n",
      "    (0.8538, 0.3364),\n",
      "    (0.9984, 0.5616),\n",
      "    (0.9984, 0.997),\n",
      "]\n",
      "\n",
      "\n",
      "Paste this into ROI_NORM_PTS in your main script:\n",
      "ROI_NORM_PTS = [\n",
      "    (0.0016, 0.997),\n",
      "    (0.0016, 0.6621),\n",
      "    (0.1407, 0.3623),\n",
      "    (0.8538, 0.3364),\n",
      "    (0.9984, 0.5616),\n",
      "    (0.9984, 0.997),\n",
      "]\n",
      "\n",
      "\n",
      "Paste this into ROI_NORM_PTS in your main script:\n",
      "ROI_NORM_PTS = [\n",
      "    (0.0016, 0.997),\n",
      "    (0.0016, 0.6621),\n",
      "    (0.1407, 0.3623),\n",
      "    (0.8538, 0.3364),\n",
      "    (0.9984, 0.5616),\n",
      "    (0.9984, 0.997),\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- calibrate_roi_click_6_points.py ---\n",
    "# Click 6 polygon points on the first video frame, get normalized (0..1) coords to paste.\n",
    "\n",
    "\n",
    "file_name = \"video_name\"\n",
    "VIDEO_PATH = f\"/path_to_your_video/{file_name}.mp4\"\n",
    "\n",
    "pts = []  # list of (x,y) in pixels\n",
    "\n",
    "def on_mouse(event, x, y, flags, userdata):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if len(pts) < 6:\n",
    "            pts.append((x, y))\n",
    "        print(f\"Point {len(pts)}: (px) {x}, {y}\")\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "ok, frame = cap.read()\n",
    "if not ok:\n",
    "    raise RuntimeError(\"Cannot read first frame.\")\n",
    "H, W = frame.shape[:2]\n",
    "\n",
    "win = \"Click 6 ROI points (clockwise), keys: u=undo, r=reset, s=save, q=quit\"\n",
    "cv2.namedWindow(win, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(win, min(1200, W), min(750, H))\n",
    "cv2.setMouseCallback(win, on_mouse)\n",
    "\n",
    "while True:\n",
    "    vis = frame.copy()\n",
    "\n",
    "    # draw already clicked points and poly lines\n",
    "    for i, (x, y) in enumerate(pts):\n",
    "        cv2.circle(vis, (x, y), 5, (0, 255, 255), -1)\n",
    "        cv2.putText(vis, str(i+1), (x+6, y-6), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2, cv2.LINE_AA)\n",
    "    if len(pts) >= 2:\n",
    "        cv2.polylines(vis, [np.array(pts, np.int32)], len(pts)==6, (0, 255, 255), 2)\n",
    "\n",
    "    # instructions\n",
    "    cv2.putText(vis, \"Left-click 6 points around the pedestrian area.\",\n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (20,20,20), 4, cv2.LINE_AA)\n",
    "    cv2.putText(vis, \"Left-click 6 points around the pedestrian area.\",\n",
    "                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(vis, \"u=undo  r=reset  s=save/print  q=quit\",\n",
    "                (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (20,20,20), 3, cv2.LINE_AA)\n",
    "    cv2.putText(vis, \"u=undo  r=reset  s=save/print  q=quit\",\n",
    "                (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(win, vis)\n",
    "    k = cv2.waitKey(10) & 0xFF\n",
    "    if k == ord('u') and pts:\n",
    "        pts.pop()\n",
    "    elif k == ord('r'):\n",
    "        pts.clear()\n",
    "    elif k == ord('s') and len(pts) == 6:\n",
    "        # normalize\n",
    "        norm = [(round(x/(W-1), 4), round(y/(H-1), 4)) for (x,y) in pts]\n",
    "        print(\"\\nPaste this into ROI_NORM_PTS in your main script:\")\n",
    "        print(\"ROI_NORM_PTS = [\")\n",
    "        for x, y in norm:\n",
    "            print(f\"    ({x}, {y}),\")\n",
    "        print(\"]\\n\")\n",
    "    elif k in [27, ord('q')]:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e2948ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using FOURCC 'mp4v' -> outputs/forbidden_zone_retinanet.mp4\n",
      "[OK] Done. Total violations = 5\n"
     ]
    }
   ],
   "source": [
    "# Settings #\n",
    "file_name = \"video_name\"  # filename stem (no extension)\n",
    "VIDEO_PATH = f\"/path_to_your_video/{file_name}.mp4\"  # full path to your video\n",
    "SAVE_PATH  = \"path_to_your_file/forbidden_zone_retinanet.mp4\"  # set to None to disable saving\n",
    "\n",
    "DET_CONF = 0.50             # detection confidence threshold (good range: 0.40â€“0.60)\n",
    "IOU_MATCH_THR = 0.20        # IoU threshold for matching\n",
    "TRACK_MAX_MISS = 12         # keep tracks a bit longer to ride through brief drops\n",
    "\n",
    "# minimal stabilization knobs #\n",
    "CENTER_THR_PX  = 160        # bottom-center distance (pixels) to keep same ID\n",
    "\n",
    "# ROI: 6 normalized points (x,y in 0..1) #\n",
    "ROI_NORM_PTS = [\n",
    "    (0.0000, 0.997),  # bottom left\n",
    "    (0.0000, 0.6621), # middle left\n",
    "    (0.1407, 0.3623), # top left\n",
    "    (0.8538, 0.3364), # top right\n",
    "    (0.9999, 0.5616), # middle right\n",
    "    (0.9999, 0.997),  # bottom right\n",
    "]\n",
    "\n",
    "\n",
    "# Colors (already in BGR for OpenCV) #\n",
    "ROI_OK_BGR     = (255, 51, 51)\n",
    "ROI_ALERT_BGR  = (0 , 0, 255)\n",
    "HUD_BG_BGR     = (0, 0, 204)\n",
    "PERSON_BGR     = (255, 255, 204)\n",
    "VEHICLE_BGR    = (153, 255, 153)\n",
    "ALPHA_FILL     = 0.30\n",
    "\n",
    "PERSON_ID   = 1\n",
    "VEHICLE_IDS = {2, 3, 4, 6, 7, 8}   # bicycle, car, motorcycle, bus, train, truck\n",
    "\n",
    "# Small helper functions #\n",
    "def scale_norm_points(norm_pts, W, H):\n",
    "    \"\"\"\n",
    "    Convert normalized points (0..1) to integer pixel coordinates for WxH frame.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for x, y in norm_pts:\n",
    "        x = float(np.clip(x, 0, 1)); y = float(np.clip(y, 0, 1))\n",
    "        out.append((int(round(x * (W - 1))), int(round(y * (H - 1)))))\n",
    "    return out\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    \"\"\"\n",
    "    Compute Intersection-over-Union between two [x1,y1,x2,y2] boxes.\n",
    "    \"\"\"\n",
    "    xA, yA = max(a[0], b[0]), max(a[1], b[1])\n",
    "    xB, yB = min(a[2], b[2]), min(a[3], b[3])\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    if inter <= 0: return 0.0\n",
    "    areaA = max(0, a[2]-a[0]) * max(0, a[3]-a[1])\n",
    "    areaB = max(0, b[2]-b[0]) * max(0, b[3]-b[1])\n",
    "    return inter / max(1e-6, (areaA + areaB - inter))\n",
    "\n",
    "def nms_xyxy(boxes, scores, iou_thr=0.60):\n",
    "    \"\"\"\n",
    "    Very small NMS to drop duplicate vehicle boxes.\n",
    "    \"\"\"\n",
    "    if len(boxes) == 0: return []\n",
    "    idxs = list(range(len(boxes)))\n",
    "    idxs.sort(key=lambda i: float(scores[i]), reverse=True)\n",
    "    keep = []\n",
    "    while idxs:\n",
    "        i = idxs.pop(0)\n",
    "        keep.append(i)\n",
    "        idxs = [j for j in idxs if iou_xyxy(boxes[i], boxes[j]) < iou_thr]\n",
    "    return keep\n",
    "\n",
    "def make_writer(path, w, h, fps):\n",
    "    \"\"\"\n",
    "    Create a cv2.VideoWriter with a few FOURCC fallbacks so it opens reliably.\n",
    "    \"\"\"\n",
    "    if path is None: return None\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    for fourcc in (\"mp4v\",\"avc1\",\"XVID\",\"MJPG\"):\n",
    "        vw = cv2.VideoWriter(str(path), cv2.VideoWriter_fourcc(*fourcc), fps, (w,h))\n",
    "        if vw.isOpened():\n",
    "            print(f\"[INFO] Using FOURCC '{fourcc}' -> {path}\")\n",
    "            return vw\n",
    "    raise RuntimeError(\"No compatible codec opened; try .avi\")\n",
    "\n",
    "# Load RetinaNet (TorchVision) #\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "try:\n",
    "    from torchvision.models.detection import retinanet_resnet50_fpn, RetinaNet_ResNet50_FPN_Weights\n",
    "    model = retinanet_resnet50_fpn(weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT).to(device).eval()\n",
    "except Exception:\n",
    "    from torchvision.models.detection import retinanet_resnet50_fpn\n",
    "    model = retinanet_resnet50_fpn(pretrained=True).to(device).eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Video, ROI, writer #\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened(): raise RuntimeError(f\"Cannot open video: {VIDEO_PATH}\")\n",
    "ok, first = cap.read();  assert ok, \"Cannot read the first frame.\"\n",
    "H, W = first.shape[:2]; fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "ROI_PTS = scale_norm_points(ROI_NORM_PTS, W, H)\n",
    "ROI_CNT = np.array(ROI_PTS, np.int32).reshape(-1, 1, 2)\n",
    "writer  = make_writer(SAVE_PATH, W, H, fps) if SAVE_PATH else None\n",
    "\n",
    "# Tiny vehicle tracker #\n",
    "class Track:\n",
    "    \"\"\"\n",
    "    Minimal vehicle track:\n",
    "    id, box, miss, hits\n",
    "    confirmed -> True after TRACK_MIN_HITS (for display only)\n",
    "    inside_prev -> inside/outside status at the previous frame (to count passes)\n",
    "    counted -> already counted since the last exit (arm/disarm)\n",
    "    \"\"\"\n",
    "    def __init__(self, tid, box):\n",
    "        self.id = tid\n",
    "        self.box = box\n",
    "        self.miss = 0\n",
    "        self.inside_prev = False  # keep as in your original -> counts first vehicle correctly\n",
    "\n",
    "tracks = []\n",
    "next_id = 1\n",
    "violations = 0\n",
    "\n",
    "# Main processing loop #\n",
    "while True:\n",
    "    ok, frame_bgr = cap.read()\n",
    "    if not ok: break\n",
    "\n",
    "    #  Detection (RetinaNet) #\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_t = torch.from_numpy(frame_rgb).permute(2,0,1).float()/255.0\n",
    "    out = model([img_t.to(device)])[0]\n",
    "\n",
    "    boxes  = out[\"boxes\"].detach().to(\"cpu\").numpy()\n",
    "    labels = out[\"labels\"].detach().to(\"cpu\").numpy()\n",
    "    scores = out[\"scores\"].detach().to(\"cpu\").numpy()\n",
    "    keep   = scores >= DET_CONF\n",
    "    boxes, labels, scores = boxes[keep], labels[keep], scores[keep]\n",
    "\n",
    "    # split persons / vehicles #\n",
    "    person_boxes  = [b for b,c in zip(boxes, labels) if c==PERSON_ID]\n",
    "    veh_boxes_all = [b for b,c in zip(boxes, labels) if c in VEHICLE_IDS]\n",
    "    veh_scores_all= [s for s,c in zip(scores, labels) if c in VEHICLE_IDS]\n",
    "\n",
    "    # extra NMS on vehicles (drops duplicate boxes around the vehicle) #\n",
    "    keep_idx = nms_xyxy(veh_boxes_all, veh_scores_all, iou_thr=0.60)\n",
    "    vehicle_boxes = [veh_boxes_all[i] for i in keep_idx]\n",
    "\n",
    "    # global greedy matching (distance first, IoU fallback) #\n",
    "    assigned_tracks = set()\n",
    "    assigned_dets   = set()\n",
    "    pairs = []\n",
    "    \n",
    "    # Build all track-det pairs with cost (smaller is better) #\n",
    "    for ti, t in enumerate(tracks):\n",
    "        tx1,ty1,tx2,ty2 = t.box\n",
    "        tcx,tcy = 0.5*(tx1+tx2), ty2\n",
    "        for dj, b in enumerate(vehicle_boxes):\n",
    "            bx1,by1,bx2,by2 = b\n",
    "            bcx,bcy = 0.5*(bx1+bx2), by2\n",
    "            dist = np.hypot(bcx-tcx, bcy-tcy)\n",
    "            iou  = iou_xyxy(t.box, b)\n",
    "            cost = dist + (1.0 - iou) * CENTER_THR_PX  # unify scales\n",
    "            pairs.append((cost, ti, dj, dist, iou))\n",
    "    pairs.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Assign best non-conflicting pairs, with gate: IoU high OR distance close #\n",
    "    for cost, ti, dj, dist, iou in pairs:\n",
    "        if ti in assigned_tracks or dj in assigned_dets: \n",
    "            continue\n",
    "        if (iou >= IOU_MATCH_THR) or (dist <= CENTER_THR_PX):\n",
    "            tracks[ti].box = vehicle_boxes[dj].tolist()\n",
    "            tracks[ti].miss = 0\n",
    "            assigned_tracks.add(ti)\n",
    "            assigned_dets.add(dj)\n",
    "\n",
    "    # Unmatched tracks: age #\n",
    "    for idx, t in enumerate(tracks):\n",
    "        if idx not in assigned_tracks:\n",
    "            t.miss += 1\n",
    "\n",
    "    # Create new tracks for unmatched dets #\n",
    "    for dj, b in enumerate(vehicle_boxes):\n",
    "        if dj in assigned_dets: \n",
    "            continue\n",
    "        tracks.append(Track(next_id, b.tolist()))\n",
    "        next_id += 1\n",
    "\n",
    "    # Prune old tracks #\n",
    "    tracks = [t for t in tracks if t.miss <= TRACK_MAX_MISS]\n",
    "\n",
    "    # Counting #\n",
    "    any_vehicle_inside = False\n",
    "    for t in tracks:\n",
    "        x1,y1,x2,y2 = t.box\n",
    "        cx, cy = 0.5*(x1+x2), y2\n",
    "        inside_now = cv2.pointPolygonTest(ROI_CNT, (cx, cy), False) >= 0\n",
    "        if inside_now: any_vehicle_inside = True\n",
    "        if (not t.inside_prev) and inside_now:\n",
    "            violations += 1\n",
    "        t.inside_prev = inside_now\n",
    "\n",
    "    # Draw ROI #\n",
    "    fill = ROI_ALERT_BGR if any_vehicle_inside else ROI_OK_BGR\n",
    "    overlay = frame_bgr.copy()\n",
    "    cv2.fillPoly(overlay, [np.array(ROI_PTS, np.int32)], fill)\n",
    "    frame_bgr = cv2.addWeighted(overlay, ALPHA_FILL, frame_bgr, 1-ALPHA_FILL, 0)\n",
    "    cv2.polylines(frame_bgr, [np.array(ROI_PTS, np.int32)], True, fill, 1)\n",
    "\n",
    "    # Draw detections #\n",
    "    for (x1,y1,x2,y2) in person_boxes:\n",
    "        x1,y1,x2,y2 = map(int,[x1,y1,x2,y2])\n",
    "        cv2.rectangle(frame_bgr,(x1,y1),(x2,y2),PERSON_BGR,1)\n",
    "        cv2.putText(frame_bgr,\"person\",(x1,max(20,y1-6)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.6,PERSON_BGR,1,cv2.LINE_AA)\n",
    "\n",
    "    for t in tracks:\n",
    "        x1,y1,x2,y2 = map(int, t.box)\n",
    "        cv2.rectangle(frame_bgr,(x1,y1),(x2,y2),VEHICLE_BGR,1)\n",
    "        cv2.putText(frame_bgr,f\"vehicle #{t.id}\",(x1,max(20,y1-6)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.6,VEHICLE_BGR,1,cv2.LINE_AA)\n",
    "\n",
    "    # HUD #\n",
    "    text = f\"Violations: {violations}\"\n",
    "    (tw, th), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 1)\n",
    "    cv2.rectangle(frame_bgr,(8,8),(8+tw+14,8+th+14),(0, 0, 0),-1)\n",
    "    cv2.putText(frame_bgr,text,(15,8+th+4),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,1.0,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "    if any_vehicle_inside:\n",
    "        alert = \"Alert\"\n",
    "        (aw, ah), _ = cv2.getTextSize(alert, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 1)\n",
    "        cxm, yb = W//2, H-20\n",
    "        cv2.rectangle(frame_bgr,(cxm-aw//2-12,yb-ah-12),(cxm+aw//2+12,yb+8),(0, 0, 0),-1)\n",
    "        cv2.putText(frame_bgr,alert,(cxm-aw//2,yb),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1.2,(0, 0, 204),1,cv2.LINE_AA)\n",
    "\n",
    "    # Show & Save #\n",
    "    if writer: writer.write(frame_bgr)\n",
    "    cv2.imshow(\"Forbidden Zone Violation (RetinaNet)\", frame_bgr)\n",
    "    if cv2.waitKey(1) & 0xFF in [27, ord('q')]: break\n",
    "\n",
    "# Cleanup #\n",
    "cap.release()\n",
    "if writer: writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"[OK] Done. Total violations = {violations}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
